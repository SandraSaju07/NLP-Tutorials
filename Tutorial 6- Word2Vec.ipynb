{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c12ffd46-bf0f-41c0-b488-41f58f82f4a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "\n",
    "from gensim.models import Word2Vec\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "55c13aab-b4b5-4640-9404-f228c56a152a",
   "metadata": {},
   "outputs": [],
   "source": [
    "paragraph = \"\"\"The Natural Language Toolkit, or more commonly NLTK, is a suite of libraries and programs for symbolic and \n",
    "statistical natural language processing (NLP) for English written in the Python programming language. It supports \n",
    "classification, tokenization, stemming, tagging, parsing, and semantic reasoning functionalities.[4] It was developed \n",
    "by Steven Bird and Edward Loper in the Department of Computer and Information Science at the University of Pennsylvania.\n",
    "[5] NLTK includes graphical demonstrations and sample data. It is accompanied by a book that explains the underlying \n",
    "concepts behind the language processing tasks supported by the toolkit,[6] plus a cookbook.[7]\n",
    "\n",
    "NLTK is intended to support research and teaching in NLP or closely related areas, including empirical linguistics, \n",
    "cognitive science, artificial intelligence, information retrieval, and machine learning.[8] NLTK has been used \n",
    "successfully as a teaching tool, as an individual study tool, and as a platform for prototyping and building research \n",
    "systems. There are 32 universities in the US and 25 countries using NLTK in their courses.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "732b3eb7-b79f-4a0a-a65b-34f61dcbbc64",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocessing the data\n",
    "text = re.sub(r'\\[[0-9]*\\]',' ',paragraph)\n",
    "text = re.sub(r'\\s+',' ',text)\n",
    "text = text.lower()\n",
    "text = re.sub(r'\\d',' ',text)\n",
    "text = re.sub(r'\\s+',' ',text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "69de94e2-41e3-4afa-902f-81c5b08e78e5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'the natural language toolkit, or more commonly nltk, is a suite of libraries and programs for symbolic and statistical natural language processing (nlp) for english written in the python programming language. it supports classification, tokenization, stemming, tagging, parsing, and semantic reasoning functionalities. it was developed by steven bird and edward loper in the department of computer and information science at the university of pennsylvania. nltk includes graphical demonstrations and sample data. it is accompanied by a book that explains the underlying concepts behind the language processing tasks supported by the toolkit, plus a cookbook. nltk is intended to support research and teaching in nlp or closely related areas, including empirical linguistics, cognitive science, artificial intelligence, information retrieval, and machine learning. nltk has been used successfully as a teaching tool, as an individual study tool, and as a platform for prototyping and building research systems. there are universities in the us and countries using nltk in their courses. '"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3d42b753-a7a2-45bf-9afc-d05accbb9263",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preparing the dataset\n",
    "sentences = nltk.sent_tokenize(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b502e058-a870-43a3-84ed-a7f102b7f8ec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['the natural language toolkit, or more commonly nltk, is a suite of libraries and programs for symbolic and statistical natural language processing (nlp) for english written in the python programming language.',\n",
       " 'it supports classification, tokenization, stemming, tagging, parsing, and semantic reasoning functionalities.',\n",
       " 'it was developed by steven bird and edward loper in the department of computer and information science at the university of pennsylvania.',\n",
       " 'nltk includes graphical demonstrations and sample data.',\n",
       " 'it is accompanied by a book that explains the underlying concepts behind the language processing tasks supported by the toolkit, plus a cookbook.',\n",
       " 'nltk is intended to support research and teaching in nlp or closely related areas, including empirical linguistics, cognitive science, artificial intelligence, information retrieval, and machine learning.',\n",
       " 'nltk has been used successfully as a teaching tool, as an individual study tool, and as a platform for prototyping and building research systems.',\n",
       " 'there are universities in the us and countries using nltk in their courses.']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2de7de9c-4c50-4ccb-95ef-edbaa46710e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences = [nltk.word_tokenize(sentence) for sentence in sentences]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "381dca5c-8265-4bda-a701-b0fbc5bee4b2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['the',\n",
       "  'natural',\n",
       "  'language',\n",
       "  'toolkit',\n",
       "  ',',\n",
       "  'or',\n",
       "  'more',\n",
       "  'commonly',\n",
       "  'nltk',\n",
       "  ',',\n",
       "  'is',\n",
       "  'a',\n",
       "  'suite',\n",
       "  'of',\n",
       "  'libraries',\n",
       "  'and',\n",
       "  'programs',\n",
       "  'for',\n",
       "  'symbolic',\n",
       "  'and',\n",
       "  'statistical',\n",
       "  'natural',\n",
       "  'language',\n",
       "  'processing',\n",
       "  '(',\n",
       "  'nlp',\n",
       "  ')',\n",
       "  'for',\n",
       "  'english',\n",
       "  'written',\n",
       "  'in',\n",
       "  'the',\n",
       "  'python',\n",
       "  'programming',\n",
       "  'language',\n",
       "  '.'],\n",
       " ['it',\n",
       "  'supports',\n",
       "  'classification',\n",
       "  ',',\n",
       "  'tokenization',\n",
       "  ',',\n",
       "  'stemming',\n",
       "  ',',\n",
       "  'tagging',\n",
       "  ',',\n",
       "  'parsing',\n",
       "  ',',\n",
       "  'and',\n",
       "  'semantic',\n",
       "  'reasoning',\n",
       "  'functionalities',\n",
       "  '.'],\n",
       " ['it',\n",
       "  'was',\n",
       "  'developed',\n",
       "  'by',\n",
       "  'steven',\n",
       "  'bird',\n",
       "  'and',\n",
       "  'edward',\n",
       "  'loper',\n",
       "  'in',\n",
       "  'the',\n",
       "  'department',\n",
       "  'of',\n",
       "  'computer',\n",
       "  'and',\n",
       "  'information',\n",
       "  'science',\n",
       "  'at',\n",
       "  'the',\n",
       "  'university',\n",
       "  'of',\n",
       "  'pennsylvania',\n",
       "  '.'],\n",
       " ['nltk',\n",
       "  'includes',\n",
       "  'graphical',\n",
       "  'demonstrations',\n",
       "  'and',\n",
       "  'sample',\n",
       "  'data',\n",
       "  '.'],\n",
       " ['it',\n",
       "  'is',\n",
       "  'accompanied',\n",
       "  'by',\n",
       "  'a',\n",
       "  'book',\n",
       "  'that',\n",
       "  'explains',\n",
       "  'the',\n",
       "  'underlying',\n",
       "  'concepts',\n",
       "  'behind',\n",
       "  'the',\n",
       "  'language',\n",
       "  'processing',\n",
       "  'tasks',\n",
       "  'supported',\n",
       "  'by',\n",
       "  'the',\n",
       "  'toolkit',\n",
       "  ',',\n",
       "  'plus',\n",
       "  'a',\n",
       "  'cookbook',\n",
       "  '.'],\n",
       " ['nltk',\n",
       "  'is',\n",
       "  'intended',\n",
       "  'to',\n",
       "  'support',\n",
       "  'research',\n",
       "  'and',\n",
       "  'teaching',\n",
       "  'in',\n",
       "  'nlp',\n",
       "  'or',\n",
       "  'closely',\n",
       "  'related',\n",
       "  'areas',\n",
       "  ',',\n",
       "  'including',\n",
       "  'empirical',\n",
       "  'linguistics',\n",
       "  ',',\n",
       "  'cognitive',\n",
       "  'science',\n",
       "  ',',\n",
       "  'artificial',\n",
       "  'intelligence',\n",
       "  ',',\n",
       "  'information',\n",
       "  'retrieval',\n",
       "  ',',\n",
       "  'and',\n",
       "  'machine',\n",
       "  'learning',\n",
       "  '.'],\n",
       " ['nltk',\n",
       "  'has',\n",
       "  'been',\n",
       "  'used',\n",
       "  'successfully',\n",
       "  'as',\n",
       "  'a',\n",
       "  'teaching',\n",
       "  'tool',\n",
       "  ',',\n",
       "  'as',\n",
       "  'an',\n",
       "  'individual',\n",
       "  'study',\n",
       "  'tool',\n",
       "  ',',\n",
       "  'and',\n",
       "  'as',\n",
       "  'a',\n",
       "  'platform',\n",
       "  'for',\n",
       "  'prototyping',\n",
       "  'and',\n",
       "  'building',\n",
       "  'research',\n",
       "  'systems',\n",
       "  '.'],\n",
       " ['there',\n",
       "  'are',\n",
       "  'universities',\n",
       "  'in',\n",
       "  'the',\n",
       "  'us',\n",
       "  'and',\n",
       "  'countries',\n",
       "  'using',\n",
       "  'nltk',\n",
       "  'in',\n",
       "  'their',\n",
       "  'courses',\n",
       "  '.']]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9efcc280-c457-4fa1-8d6b-3d67fc47354f",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(sentences)):\n",
    "    sentences[i] = [word for word in sentences[i] if word not in stopwords.words('english')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "cf66bbbf-bd51-4fd2-9d5e-643a6c6c7f4b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['natural',\n",
       "  'language',\n",
       "  'toolkit',\n",
       "  ',',\n",
       "  'commonly',\n",
       "  'nltk',\n",
       "  ',',\n",
       "  'suite',\n",
       "  'libraries',\n",
       "  'programs',\n",
       "  'symbolic',\n",
       "  'statistical',\n",
       "  'natural',\n",
       "  'language',\n",
       "  'processing',\n",
       "  '(',\n",
       "  'nlp',\n",
       "  ')',\n",
       "  'english',\n",
       "  'written',\n",
       "  'python',\n",
       "  'programming',\n",
       "  'language',\n",
       "  '.'],\n",
       " ['supports',\n",
       "  'classification',\n",
       "  ',',\n",
       "  'tokenization',\n",
       "  ',',\n",
       "  'stemming',\n",
       "  ',',\n",
       "  'tagging',\n",
       "  ',',\n",
       "  'parsing',\n",
       "  ',',\n",
       "  'semantic',\n",
       "  'reasoning',\n",
       "  'functionalities',\n",
       "  '.'],\n",
       " ['developed',\n",
       "  'steven',\n",
       "  'bird',\n",
       "  'edward',\n",
       "  'loper',\n",
       "  'department',\n",
       "  'computer',\n",
       "  'information',\n",
       "  'science',\n",
       "  'university',\n",
       "  'pennsylvania',\n",
       "  '.'],\n",
       " ['nltk', 'includes', 'graphical', 'demonstrations', 'sample', 'data', '.'],\n",
       " ['accompanied',\n",
       "  'book',\n",
       "  'explains',\n",
       "  'underlying',\n",
       "  'concepts',\n",
       "  'behind',\n",
       "  'language',\n",
       "  'processing',\n",
       "  'tasks',\n",
       "  'supported',\n",
       "  'toolkit',\n",
       "  ',',\n",
       "  'plus',\n",
       "  'cookbook',\n",
       "  '.'],\n",
       " ['nltk',\n",
       "  'intended',\n",
       "  'support',\n",
       "  'research',\n",
       "  'teaching',\n",
       "  'nlp',\n",
       "  'closely',\n",
       "  'related',\n",
       "  'areas',\n",
       "  ',',\n",
       "  'including',\n",
       "  'empirical',\n",
       "  'linguistics',\n",
       "  ',',\n",
       "  'cognitive',\n",
       "  'science',\n",
       "  ',',\n",
       "  'artificial',\n",
       "  'intelligence',\n",
       "  ',',\n",
       "  'information',\n",
       "  'retrieval',\n",
       "  ',',\n",
       "  'machine',\n",
       "  'learning',\n",
       "  '.'],\n",
       " ['nltk',\n",
       "  'used',\n",
       "  'successfully',\n",
       "  'teaching',\n",
       "  'tool',\n",
       "  ',',\n",
       "  'individual',\n",
       "  'study',\n",
       "  'tool',\n",
       "  ',',\n",
       "  'platform',\n",
       "  'prototyping',\n",
       "  'building',\n",
       "  'research',\n",
       "  'systems',\n",
       "  '.'],\n",
       " ['universities', 'us', 'countries', 'using', 'nltk', 'courses', '.']]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "43a3e7e9-e3b7-4b1e-a894-6f5e164df943",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training the Word2Vec model\n",
    "model = Word2Vec(sentences, min_count = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "e4e95cb8-270d-4fa3-a98b-ba4e5aca6386",
   "metadata": {},
   "outputs": [],
   "source": [
    "words = model.wv.index_to_key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "bd85707f-329c-4e91-acb5-d8ce565b9491",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[',',\n",
       " '.',\n",
       " 'nltk',\n",
       " 'language',\n",
       " 'natural',\n",
       " 'tool',\n",
       " 'nlp',\n",
       " 'teaching',\n",
       " 'processing',\n",
       " 'research',\n",
       " 'information',\n",
       " 'science',\n",
       " 'toolkit',\n",
       " 'functionalities',\n",
       " 'tagging',\n",
       " 'parsing',\n",
       " 'semantic',\n",
       " 'reasoning',\n",
       " 'computer',\n",
       " 'developed',\n",
       " 'department',\n",
       " 'bird',\n",
       " 'university',\n",
       " 'edward',\n",
       " 'loper',\n",
       " 'steven',\n",
       " 'supports',\n",
       " 'stemming',\n",
       " '(',\n",
       " 'commonly',\n",
       " 'suite',\n",
       " 'libraries',\n",
       " 'programs',\n",
       " 'symbolic',\n",
       " 'statistical',\n",
       " ')',\n",
       " 'tokenization',\n",
       " 'english',\n",
       " 'written',\n",
       " 'python',\n",
       " 'programming',\n",
       " 'includes',\n",
       " 'classification',\n",
       " 'pennsylvania',\n",
       " 'courses',\n",
       " 'graphical',\n",
       " 'using',\n",
       " 'cognitive',\n",
       " 'artificial',\n",
       " 'intelligence',\n",
       " 'retrieval',\n",
       " 'machine',\n",
       " 'learning',\n",
       " 'used',\n",
       " 'successfully',\n",
       " 'individual',\n",
       " 'study',\n",
       " 'platform',\n",
       " 'prototyping',\n",
       " 'building',\n",
       " 'systems',\n",
       " 'universities',\n",
       " 'us',\n",
       " 'countries',\n",
       " 'linguistics',\n",
       " 'empirical',\n",
       " 'including',\n",
       " 'behind',\n",
       " 'sample',\n",
       " 'data',\n",
       " 'accompanied',\n",
       " 'book',\n",
       " 'explains',\n",
       " 'underlying',\n",
       " 'concepts',\n",
       " 'tasks',\n",
       " 'areas',\n",
       " 'supported',\n",
       " 'plus',\n",
       " 'cookbook',\n",
       " 'intended',\n",
       " 'support',\n",
       " 'closely',\n",
       " 'related',\n",
       " 'demonstrations']"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "ac052f91-b66b-411f-bd51-358e7a4e9894",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Finding word vectors of words\n",
    "vector = model.wv['nlp']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "16c4a996-8628-4b91-b4a0-dec587467354",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 8.1726359e-03, -4.4368720e-03, -1.0604985e-03,  1.0047242e-03,\n",
       "       -1.2601112e-04,  1.0813555e-03,  6.1618220e-03,  5.6514840e-05,\n",
       "       -3.2469102e-03, -1.5419513e-03,  5.9045628e-03,  1.4599644e-03,\n",
       "       -7.3814840e-04,  9.3515525e-03, -4.9035028e-03, -8.4453251e-04,\n",
       "        9.1982149e-03,  6.7283651e-03,  1.5420523e-03, -8.9206202e-03,\n",
       "        1.2204704e-03, -2.2575150e-03,  9.3878973e-03,  1.1855743e-03,\n",
       "        1.4732252e-03,  2.4094405e-03, -1.8716689e-03, -4.9765739e-03,\n",
       "        2.4388260e-04, -2.0583884e-03,  6.6065439e-03,  8.9358194e-03,\n",
       "       -6.2980177e-04,  2.9127258e-03, -6.1295796e-03,  1.7528301e-03,\n",
       "       -6.8577281e-03, -8.7177018e-03, -5.9367321e-03, -8.9980662e-03,\n",
       "        7.2956597e-03, -5.7945363e-03,  8.3071953e-03, -7.2237873e-03,\n",
       "        3.4168113e-03,  9.7098676e-03, -7.8436257e-03, -9.9321278e-03,\n",
       "       -4.2758929e-03, -2.6890978e-03, -2.4801286e-04, -8.8512450e-03,\n",
       "       -8.6515909e-03,  2.8155039e-03, -8.2360683e-03, -9.0807872e-03,\n",
       "       -2.2814395e-03, -8.6140949e-03, -7.1058995e-03, -8.4168976e-03,\n",
       "       -2.9097198e-04, -4.5291618e-03,  6.6537610e-03,  1.5397259e-03,\n",
       "       -3.3549627e-03,  6.1928215e-03, -5.9944196e-03, -4.6270578e-03,\n",
       "       -7.2635589e-03, -4.3200217e-03, -1.8522984e-03,  6.5029580e-03,\n",
       "       -2.7438260e-03,  4.9363654e-03,  6.9903126e-03, -7.4775429e-03,\n",
       "        4.5779967e-03,  6.1419699e-03, -3.0058648e-03,  6.5913340e-03,\n",
       "        6.0750809e-03, -6.4407489e-03, -6.8393876e-03,  2.5498515e-03,\n",
       "       -1.6493428e-03, -6.0792910e-03,  9.5882667e-03, -5.0954809e-03,\n",
       "       -6.5492489e-03, -9.2570299e-05, -2.6334627e-03,  4.5999378e-04,\n",
       "       -3.5569172e-03, -3.7598211e-04, -6.3914340e-04,  8.5037522e-04,\n",
       "        8.1919860e-03, -5.7406016e-03, -1.6558637e-03,  5.5398881e-03],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "2aaffec3-5d6a-4d1f-a97b-657efc669c72",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(vector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "b212972f-0908-4437-a54e-61e22f2edc5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Most similar words\n",
    "similar = model.wv.most_similar('nlp')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "182563a6-eb5d-4679-87c6-e418811651b9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('english', 0.3501066565513611),\n",
       " ('(', 0.3038422167301178),\n",
       " ('cognitive', 0.25153568387031555),\n",
       " ('underlying', 0.2241838127374649),\n",
       " ('supports', 0.1774691939353943),\n",
       " ('semantic', 0.16476021707057953),\n",
       " ('steven', 0.16339156031608582),\n",
       " ('classification', 0.15500327944755554),\n",
       " ('us', 0.15340973436832428),\n",
       " ('nltk', 0.14661931991577148)]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "similar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "d1c1a8ca-ba38-4305-be1c-edc6994ef53d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('science', 0.31321951746940613),\n",
       " ('countries', 0.2339349240064621),\n",
       " ('programs', 0.2239091396331787),\n",
       " ('.', 0.18436744809150696),\n",
       " ('reasoning', 0.17269477248191833),\n",
       " ('steven', 0.16309760510921478),\n",
       " ('symbolic', 0.15654703974723816),\n",
       " ('computer', 0.15599776804447174),\n",
       " ('bird', 0.12011037766933441),\n",
       " ('commonly', 0.11530475318431854)]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.wv.most_similar('machine')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "c5dcf14f-ddc3-420b-a414-6eb2ad5985ad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('processing', 0.2852904498577118),\n",
       " ('using', 0.27052703499794006),\n",
       " ('programming', 0.25975358486175537),\n",
       " ('prototyping', 0.25381964445114136),\n",
       " ('related', 0.2050858438014984),\n",
       " ('.', 0.1885765641927719),\n",
       " ('support', 0.16728731989860535),\n",
       " ('suite', 0.1421465426683426),\n",
       " ('areas', 0.14012593030929565),\n",
       " ('tagging', 0.10794893652200699)]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.wv.most_similar('stemming')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "981c70fc-59c0-4e8d-b654-379858e1cd85",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
