{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "11e45982",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "showing info https://raw.githubusercontent.com/nltk/nltk_data/gh-pages/index.xml\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\Ciya\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download()\n",
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bc65f6f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "paragraph = \"\"\"The Natural Language Toolkit, or more commonly NLTK, is a suite of libraries and programs for symbolic and \n",
    "statistical natural language processing (NLP) for English written in the Python programming language. It supports \n",
    "classification, tokenization, stemming, tagging, parsing, and semantic reasoning functionalities.[4] It was developed \n",
    "by Steven Bird and Edward Loper in the Department of Computer and Information Science at the University of Pennsylvania.\n",
    "[5] NLTK includes graphical demonstrations and sample data. It is accompanied by a book that explains the underlying \n",
    "concepts behind the language processing tasks supported by the toolkit,[6] plus a cookbook.[7]\n",
    "\n",
    "NLTK is intended to support research and teaching in NLP or closely related areas, including empirical linguistics, \n",
    "cognitive science, artificial intelligence, information retrieval, and machine learning.[8] NLTK has been used \n",
    "successfully as a teaching tool, as an individual study tool, and as a platform for prototyping and building research \n",
    "systems. There are 32 universities in the US and 25 countries using NLTK in their courses.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8bd2310c",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences = nltk.sent_tokenize(paragraph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "dca10bd1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['The Natural Language Toolkit, or more commonly NLTK, is a suite of libraries and programs for symbolic and \\nstatistical natural language processing (NLP) for English written in the Python programming language.',\n",
       " 'It supports \\nclassification, tokenization, stemming, tagging, parsing, and semantic reasoning functionalities.',\n",
       " '[4] It was developed \\nby Steven Bird and Edward Loper in the Department of Computer and Information Science at the University of Pennsylvania.',\n",
       " '[5] NLTK includes graphical demonstrations and sample data.',\n",
       " 'It is accompanied by a book that explains the underlying \\nconcepts behind the language processing tasks supported by the toolkit,[6] plus a cookbook.',\n",
       " '[7]\\n\\nNLTK is intended to support research and teaching in NLP or closely related areas, including empirical linguistics, \\ncognitive science, artificial intelligence, information retrieval, and machine learning.',\n",
       " '[8] NLTK has been used \\nsuccessfully as a teaching tool, as an individual study tool, and as a platform for prototyping and building research \\nsystems.',\n",
       " 'There are 32 universities in the US and 25 countries using NLTK in their courses.']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e7d2e520",
   "metadata": {},
   "outputs": [],
   "source": [
    "words = nltk.word_tokenize(paragraph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6fc35718",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['The',\n",
       " 'Natural',\n",
       " 'Language',\n",
       " 'Toolkit',\n",
       " ',',\n",
       " 'or',\n",
       " 'more',\n",
       " 'commonly',\n",
       " 'NLTK',\n",
       " ',',\n",
       " 'is',\n",
       " 'a',\n",
       " 'suite',\n",
       " 'of',\n",
       " 'libraries',\n",
       " 'and',\n",
       " 'programs',\n",
       " 'for',\n",
       " 'symbolic',\n",
       " 'and',\n",
       " 'statistical',\n",
       " 'natural',\n",
       " 'language',\n",
       " 'processing',\n",
       " '(',\n",
       " 'NLP',\n",
       " ')',\n",
       " 'for',\n",
       " 'English',\n",
       " 'written',\n",
       " 'in',\n",
       " 'the',\n",
       " 'Python',\n",
       " 'programming',\n",
       " 'language',\n",
       " '.',\n",
       " 'It',\n",
       " 'supports',\n",
       " 'classification',\n",
       " ',',\n",
       " 'tokenization',\n",
       " ',',\n",
       " 'stemming',\n",
       " ',',\n",
       " 'tagging',\n",
       " ',',\n",
       " 'parsing',\n",
       " ',',\n",
       " 'and',\n",
       " 'semantic',\n",
       " 'reasoning',\n",
       " 'functionalities',\n",
       " '.',\n",
       " '[',\n",
       " '4',\n",
       " ']',\n",
       " 'It',\n",
       " 'was',\n",
       " 'developed',\n",
       " 'by',\n",
       " 'Steven',\n",
       " 'Bird',\n",
       " 'and',\n",
       " 'Edward',\n",
       " 'Loper',\n",
       " 'in',\n",
       " 'the',\n",
       " 'Department',\n",
       " 'of',\n",
       " 'Computer',\n",
       " 'and',\n",
       " 'Information',\n",
       " 'Science',\n",
       " 'at',\n",
       " 'the',\n",
       " 'University',\n",
       " 'of',\n",
       " 'Pennsylvania',\n",
       " '.',\n",
       " '[',\n",
       " '5',\n",
       " ']',\n",
       " 'NLTK',\n",
       " 'includes',\n",
       " 'graphical',\n",
       " 'demonstrations',\n",
       " 'and',\n",
       " 'sample',\n",
       " 'data',\n",
       " '.',\n",
       " 'It',\n",
       " 'is',\n",
       " 'accompanied',\n",
       " 'by',\n",
       " 'a',\n",
       " 'book',\n",
       " 'that',\n",
       " 'explains',\n",
       " 'the',\n",
       " 'underlying',\n",
       " 'concepts',\n",
       " 'behind',\n",
       " 'the',\n",
       " 'language',\n",
       " 'processing',\n",
       " 'tasks',\n",
       " 'supported',\n",
       " 'by',\n",
       " 'the',\n",
       " 'toolkit',\n",
       " ',',\n",
       " '[',\n",
       " '6',\n",
       " ']',\n",
       " 'plus',\n",
       " 'a',\n",
       " 'cookbook',\n",
       " '.',\n",
       " '[',\n",
       " '7',\n",
       " ']',\n",
       " 'NLTK',\n",
       " 'is',\n",
       " 'intended',\n",
       " 'to',\n",
       " 'support',\n",
       " 'research',\n",
       " 'and',\n",
       " 'teaching',\n",
       " 'in',\n",
       " 'NLP',\n",
       " 'or',\n",
       " 'closely',\n",
       " 'related',\n",
       " 'areas',\n",
       " ',',\n",
       " 'including',\n",
       " 'empirical',\n",
       " 'linguistics',\n",
       " ',',\n",
       " 'cognitive',\n",
       " 'science',\n",
       " ',',\n",
       " 'artificial',\n",
       " 'intelligence',\n",
       " ',',\n",
       " 'information',\n",
       " 'retrieval',\n",
       " ',',\n",
       " 'and',\n",
       " 'machine',\n",
       " 'learning',\n",
       " '.',\n",
       " '[',\n",
       " '8',\n",
       " ']',\n",
       " 'NLTK',\n",
       " 'has',\n",
       " 'been',\n",
       " 'used',\n",
       " 'successfully',\n",
       " 'as',\n",
       " 'a',\n",
       " 'teaching',\n",
       " 'tool',\n",
       " ',',\n",
       " 'as',\n",
       " 'an',\n",
       " 'individual',\n",
       " 'study',\n",
       " 'tool',\n",
       " ',',\n",
       " 'and',\n",
       " 'as',\n",
       " 'a',\n",
       " 'platform',\n",
       " 'for',\n",
       " 'prototyping',\n",
       " 'and',\n",
       " 'building',\n",
       " 'research',\n",
       " 'systems',\n",
       " '.',\n",
       " 'There',\n",
       " 'are',\n",
       " '32',\n",
       " 'universities',\n",
       " 'in',\n",
       " 'the',\n",
       " 'US',\n",
       " 'and',\n",
       " '25',\n",
       " 'countries',\n",
       " 'using',\n",
       " 'NLTK',\n",
       " 'in',\n",
       " 'their',\n",
       " 'courses',\n",
       " '.']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86af0bd2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
